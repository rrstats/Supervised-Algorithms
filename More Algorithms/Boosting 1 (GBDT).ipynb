{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a9da5c-046b-4676-8c30-a290e7fb538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0068dcd-cac9-4819-a58c-eafe3064a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gdown 1h86M8si2YT-aI4Zec1MeMP_mPYsLPy5F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac429228-42fa-4af8-ba8f-0a322a0d9f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('HR-Employee-Attrition.csv')\n",
    "df.drop(['EmployeeCount', 'EmployeeNumber', 'StandardHours', 'Over18'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65b546-21f2-4b6a-a6ed-dcc6c5044e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c3a99ff-6611-48ec-bff6-c3c917f5d9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attrition: 2\n",
      "BusinessTravel: 3\n",
      "Department: 3\n",
      "EducationField: 6\n",
      "Gender: 2\n",
      "JobRole: 9\n",
      "MaritalStatus: 3\n",
      "OverTime: 2\n",
      "Attrition\n",
      "Gender\n",
      "OverTime\n",
      "Number transactions X_train dataset:  (1102, 33)\n",
      "Number transactions y_train dataset:  (1102,)\n",
      "Number transactions X_test dataset:  (368, 33)\n",
      "Number transactions y_test dataset:  (368,)\n",
      "Resampled dataset shape Counter({0: 924, 1: 924})\n"
     ]
    }
   ],
   "source": [
    "def unique_vals(col):\n",
    "\n",
    "  if col.dtype == \"object\":\n",
    "\n",
    "    print(f'{col.name}: {col.nunique()}')\n",
    "\n",
    "df.apply(lambda col: unique_vals(col))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "def label_encode(ser):\n",
    "\n",
    "    if ser.dtype==\"object\" and ser.nunique() <= 2:\n",
    "      print(ser.name)\n",
    "\n",
    "      le.fit(ser)\n",
    "      ser = le.transform(ser)\n",
    "\n",
    "    return ser\n",
    "\n",
    "df = df.apply(lambda col: label_encode(col))\n",
    "\n",
    "\n",
    "\n",
    "# convert rest of categorical variable into dummy\n",
    "df = pd.get_dummies(df, columns = [\"BusinessTravel\", \"Department\", \"MaritalStatus\"], drop_first = True)\n",
    "\n",
    "\n",
    "target = df['Attrition'].copy()\n",
    "df = df.drop([\"Attrition\"], axis = 1)\n",
    "type(target)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Since we have class imbalance (i.e. more employees with turnover=0 than turnover=1)\n",
    "# let's use stratify=y to maintain the same ratio as in the training dataset when splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df,\n",
    "                                                    target,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=7,\n",
    "                                                    stratify=target)\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "ce_target = ce.TargetEncoder(cols = ['EducationField', 'JobRole'])\n",
    "X_train = ce_target.fit_transform(X_train, y_train)\n",
    "X_test = ce_target.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Upsampling using SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "smt = SMOTE()\n",
    "X_sm, y_sm = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape {}'.format(Counter(y_sm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a27e78-f5fc-457a-8a6e-68d6ca401426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c190b-2de1-4c98-a0bb-7d8efe29db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoositingClassifier(n_estimators = 150)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
